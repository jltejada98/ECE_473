{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-78b4eb8add6c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'load_ext'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'autoreload'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'autoreload'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'2'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'matplotlib'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'inline'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mload_breast_cancer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mrun_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2342\u001B[0m                 \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'local_ns'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_local_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstack_depth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2343\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2344\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2345\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2346\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-101>\u001B[0m in \u001B[0;36mmatplotlib\u001B[0;34m(self, line)\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/IPython/core/magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(f, *a, **k)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mcall\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/IPython/core/magics/pylab.py\u001B[0m in \u001B[0;36mmatplotlib\u001B[0;34m(self, line)\u001B[0m\n\u001B[1;32m     97\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Available matplotlib backends: %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mbackends_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m             \u001B[0mgui\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshell\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_matplotlib\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgui\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgui\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgui\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    100\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_show_matplotlib_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgui\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackend\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/ipykernel/zmqshell.py\u001B[0m in \u001B[0;36menable_matplotlib\u001B[0;34m(self, gui)\u001B[0m\n\u001B[1;32m    599\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    600\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0menable_matplotlib\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgui\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 601\u001B[0;31m         \u001B[0mgui\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mZMQInteractiveShell\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_matplotlib\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgui\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    602\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    603\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0mipykernel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpylab\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackend_inline\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconfigure_inline_support\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36menable_matplotlib\u001B[0;34m(self, gui)\u001B[0m\n\u001B[1;32m   3511\u001B[0m         \"\"\"\n\u001B[1;32m   3512\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0mIPython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpylabtools\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3513\u001B[0;31m         \u001B[0mgui\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbackend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind_gui_and_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgui\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpylab_gui_select\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3514\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3515\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mgui\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m'inline'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/IPython/core/pylabtools.py\u001B[0m in \u001B[0;36mfind_gui_and_backend\u001B[0;34m(gui, gui_select)\u001B[0m\n\u001B[1;32m    278\u001B[0m     \"\"\"\n\u001B[1;32m    279\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 280\u001B[0;31m     \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    281\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    282\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mgui\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mgui\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m'auto'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "seed = 222\n",
    "\n",
    "\n",
    "import hw3_submission_sol as hw3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Check the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print dataset information to see is correctly loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cancer = load_breast_cancer()\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(data_cancer.data, data_cancer.target, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('A sample from the training dataset:\\n')\n",
    "print(X_train_cancer[0])\n",
    "print()\n",
    "print('size of the training dataset : ', X_train_cancer.shape)\n",
    "print('number of the training dataset : ', X_train_cancer.shape[0])\n",
    "print('dimension of the training dataset : ', X_train_cancer.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive_Bayes = hw3.Gaussian_Naive_Bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive_Bayes.fit(X_train_cancer, y_train_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_by_class(self):\n",
    "        \"\"\"\n",
    "        With the given input dataset (self.x, self.y), generate 3 dictionaries to calculate class-wise mean and variance of the data.\n",
    "        - self.x_by_class : A dictionary of numpy arraies with the keys as each class label and values as data with such label.\n",
    "        - self.mean_by_class : A dictionary of numpy arraies with the keys as each class label and values as mean of the data with such label.\n",
    "        - self.std_by_class : A dictionary of numpy arraies with the keys as each class label and values as standard deviation of the data with such \n",
    "        label.\n",
    "        - self.y_prior : A numpy array of shape (C,) containing prior probability of each class\n",
    "        \"\"\"\n",
    "        self.x_by_class = dict()\n",
    "        self.mean_by_class = dict()\n",
    "        self.std_by_class = dict()\n",
    "        self.y_prior = None\n",
    "        \n",
    "        ############################################################\n",
    "        ############################################################\n",
    "        # BEGIN_YOUR_CODE\n",
    "        # Generate dictionaries.\n",
    "        # hint : to see all unique y labels, you might use np.unique function, e.g., np.unique(self.y)\n",
    "        \n",
    "        self.std\n",
    "        self.mean\n",
    "\n",
    "        pass\n",
    "\n",
    "        # END_YOUR_CODE\n",
    "        ############################################################\n",
    "        ############################################################   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Naive_Bayes.x_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Naive_Bayes.mean_by_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Naive_Bayes.std_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(Naive_Bayes.y_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    ############################################################\n",
    "    ############################################################\n",
    "    # BEGIN_YOUR_CODE\n",
    "    # calculate \n",
    "        pass\n",
    "\n",
    "    # END_YOUR_CODE\n",
    "    ############################################################\n",
    "    ############################################################\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction : (N x C) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive_Bayes.predict(X_test_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the acquired mean and variance,we can compute probability from gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x, \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\Big(-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2\\Big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(x_1 = 3.37 | y = \\text{1} ) = f(3.37, \\mu_{11}, \\sigma_{11})$$\\\n",
    "$$P(x_1 = 3.37 | y = \\text{0} ) = f(3.37, \\mu_{10}, \\sigma_{10})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive_Bayes.calc_gaussian_dist(X_test_cancer[0], Naive_Bayes.mean_by_class[0], Naive_Bayes.std_by_class[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider each feature as each 'word' in the previous spam detection hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.log(Naive_Bayes.calc_gaussian_dist(X_test_cancer[0], Naive_Bayes.mean_by_class[0], Naive_Bayes.std_by_class[0]))) + prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Naive_Bayes.predict(X_test_cancer).argmax(-1) == y_test_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Two-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "iteration = 2000\n",
    "learning_rate = 1e-3\n",
    "reg = 1e-3\n",
    "\n",
    "hidden_size = 64\n",
    "\n",
    "NN = hw3.Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = X_train_cancer.shape[1]\n",
    "num_train = X_train_cancer.shape[0]\n",
    "\n",
    "#initialize W\n",
    "if NN.W1 == None:\n",
    "    NN.W1 = 0.001 * np.random.randn(dim, NN.hidden_size)\n",
    "    NN.b1 = 0\n",
    "\n",
    "    NN.W2 = 0.001 * np.random.randn(NN.hidden_size, NN.output_size)\n",
    "    NN.b2 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ind = np.random.choice(num_train, batch_size)\n",
    "\n",
    "x_batch = X_train_cancer[batch_ind]\n",
    "y_batch = y_train_cancer[batch_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an input batch $X$, we can compute NN as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$g_1 = W_1^TX + b_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_1 = ReLU(g_1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where, ReLU(x) = x if x>0, else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$g_2 = W_2^Th_1 + b_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat y = \\sigma(g_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = ###\n",
    "h1 = NN.activation(g1)\n",
    "\n",
    "g2 = ###\n",
    "\n",
    "y_hat = NN.sigmoid(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on that we calculate binary cross entropy loss $L_{CE}$ to update $W, b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$L_{CE} = -\\frac{1}{|B|}\\sum_{B} \\big( y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i) \\big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, gradient = NN.loss(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that gradients match with the shape with its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NN.W1.shape, gradient['dW1'].shape)\n",
    "print(NN.W2.shape, gradient['dW2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to compute the derivative of $L$ w.r.t. $W, b$ to update $W, b$.\\ with mini-batch stochastic gradient descent method.\\\n",
    "This can be done with chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$L_{CE} = -\\frac{1}{|B|}\\sum_{B} \\big( y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i) \\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\hat{y}} = \\sigma(g_2) = \\frac{1}{1+ \\exp(-g_2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$g_2 = W_2^Th_1 + b_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_1 = ReLU(g_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$g_1 = W_1^TX + b_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating $W_2, b_2$ is similar to what we did in Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial W_2} = \n",
    "\\frac{\\partial L}{\\partial \\hat y} \\cdot \\frac{\\partial \\hat y}{\\partial g_2} \\cdot \\frac{\\partial g_2}{\\partial W_2} $$ \\\n",
    "$$\\frac{\\partial L}{\\partial b_2} = \\frac{\\partial L}{\\partial \\hat y} \\cdot \\frac{\\partial \\hat y}{\\partial g_2} \\cdot \\frac{\\partial g_2}{\\partial b_2} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update $W_1, b_1$, we back propagate the gradient as below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$L_{CE} = -\\frac{1}{|B|}\\sum_{B} \\big( y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i) \\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\hat{y}} = \\sigma(g_2) = \\frac{1}{1+ \\exp(-g_2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$g_2 = W_2^Th_1 + b_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_1 = ReLU(g_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$g_1 = W_1^TX + b_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial W_1} = \n",
    "\\frac{\\partial L}{\\partial \\hat y} \\cdot \\frac{\\partial \\hat y}{\\partial g_2} \\cdot \\frac{\\partial g_2}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial g_1} \\cdot \\frac{\\partial g_1}{\\partial W_1}$$ \\\n",
    "$$\\frac{\\partial L}{\\partial b_1} = \n",
    "\\frac{\\partial L}{\\partial \\hat y} \\cdot \\frac{\\partial \\hat y}{\\partial g_2} \\cdot \\frac{\\partial g_2}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial g_1} \\cdot \\frac{\\partial g_1}{\\partial b_1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily compute  intermediate gradients as described in previous overview session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$   \n",
    "    ReLU(x) = \\left\\{\\begin{array}{lr}\n",
    "        x, & \\text{for } 0\\leq x\\\\\n",
    "        0, & \\text{for } else \\\\\n",
    "        \\end{array}\\right\\} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of this would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$   \n",
    "    \\frac{\\partial ReLU(x)}{\\partial x}\n",
    "        = \\left\\{\\begin{array}{lr}\n",
    "        1, & \\text{for } 0\\leq x\\\\\n",
    "        0, & \\text{for } else \\\\\n",
    "        \\end{array}\\right\\} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, gradient = NN.loss(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then with the $dW, db$ above, you can update $W, b$ with a given learning rate $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$W \\leftarrow W - \\alpha \\cdot  dW$$\\\n",
    "$$b \\leftarrow b - \\alpha \\cdot  db$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Regression.W1 <- Update\n",
    "Logistic_Regression.W2 <- Update\n",
    "Logistic_Regression.b1 <- Update\n",
    "Logistic_Regression.b2 <- Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}